{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Image\n",
    "from pandas import get_dummies\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# Config the matlotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./merged_player.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3186.000000\n",
       "mean        6.677269\n",
       "std         0.383715\n",
       "min         5.190000\n",
       "25%         6.410000\n",
       "50%         6.700000\n",
       "75%         6.920000\n",
       "max         8.460000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_column_list = ['Unnamed: 0.1', 'flag', 'full_time', 'half_time', 'league', 'mins', 'motm', 'name', 'player_number', 'position', 'ps_y', 'rating', 'team_name']\n",
    "data0 = data.drop(drop_column_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data0 = data0.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3186, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allPlayer = data0.get_values()\n",
    "np.shape(X_allPlayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = allPlayer[:, :-1]\n",
    "y = allPlayer[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=7).fit(X)\n",
    "X_transformed = pca.transform(X)\n",
    "\n",
    "y = get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert to np arrays so that we can use with Tensorflow\n",
    "X_train = np.array(X_train).astype(np.float32)\n",
    "X_test  = np.array(X_test).astype(np.float32)\n",
    "y_train = np.array(y_train).astype(np.float32)\n",
    "y_test  = np.array(y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2230, 7) (2230, 6)\n",
      "(956, 7) (956, 6)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train), np.shape(y_train))\n",
    "print(np.shape(X_test), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(2230, 7), dtype=float32)\n",
      "Tensor(\"Const_1:0\", shape=(2230, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "training_size = X_train.shape[1]\n",
    "test_size = X_test.shape[1]\n",
    "num_features = 7\n",
    "num_labels = 6\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "num_hidden = 3\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_set    = tf.constant(X_train)\n",
    "    tf_train_labels = tf.constant(y_train)\n",
    "    tf_valid_set    = tf.constant(X_test)\n",
    " \n",
    "    \n",
    "    print(tf_train_set)\n",
    "    print(tf_train_labels)\n",
    "    \n",
    "    ## Note, since there is only 1 layer there are actually no hidden layers... but if there were\n",
    "    ## there would be num_hidden\n",
    "    weights_1 = tf.Variable(tf.truncated_normal([num_features, num_hidden]))\n",
    "    weights_2 = tf.Variable(tf.truncated_normal([num_hidden, num_labels]))\n",
    "    ## tf.zeros Automaticaly adjusts rows to input data batch size\n",
    "    bias_1 = tf.Variable(tf.zeros([num_hidden]))\n",
    "    bias_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    \n",
    "    logits_1 = tf.matmul(tf_train_set , weights_1 ) + bias_1\n",
    "    rel_1 = tf.nn.relu(logits_1)\n",
    "    logits_2 = tf.matmul(rel_1, weights_2) + bias_2\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits_2, labels=tf_train_labels))\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(.005).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "    \n",
    "    ## Training prediction\n",
    "    predict_train = tf.nn.softmax(logits_2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Validation prediction\n",
    "    logits_1_val = tf.matmul(tf_valid_set, weights_1) + bias_1\n",
    "    rel_1_val    = tf.nn.relu(logits_1_val)\n",
    "    logits_2_val = tf.matmul(rel_1_val, weights_2) + bias_2\n",
    "    predict_valid = tf.nn.softmax(logits_2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-42-b6aeaff3c59a>:3: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "13.7496\n",
      "Loss at step 0: 13.749603\n",
      "Training accuracy: 17.1%\n",
      "Validation accuracy: 18.2%\n",
      "Loss at step 1000: 1.701867\n",
      "Training accuracy: 26.6%\n",
      "Validation accuracy: 25.9%\n",
      "Loss at step 2000: 1.688064\n",
      "Training accuracy: 28.2%\n",
      "Validation accuracy: 22.7%\n",
      "Loss at step 3000: 1.688489\n",
      "Training accuracy: 28.3%\n",
      "Validation accuracy: 24.3%\n",
      "Loss at step 4000: 1.687167\n",
      "Training accuracy: 28.5%\n",
      "Validation accuracy: 24.3%\n",
      "Loss at step 5000: 1.690273\n",
      "Training accuracy: 27.8%\n",
      "Validation accuracy: 25.3%\n",
      "Loss at step 6000: 1.687155\n",
      "Training accuracy: 28.1%\n",
      "Validation accuracy: 24.2%\n",
      "Loss at step 7000: 1.754871\n",
      "Training accuracy: 19.7%\n",
      "Validation accuracy: 18.2%\n",
      "Loss at step 8000: 1.754236\n",
      "Training accuracy: 19.7%\n",
      "Validation accuracy: 18.3%\n",
      "Loss at step 9000: 1.753246\n",
      "Training accuracy: 19.6%\n",
      "Validation accuracy: 18.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10000\n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(loss.eval())\n",
    "    for step in range(num_steps):\n",
    "        _,l, predictions = session.run([optimizer, loss, predict_train])\n",
    "        \n",
    "        if (step % 1000 == 0):\n",
    "#               print(predictions[3:6])\n",
    "              print('Loss at step %d: %f' % (step, l))\n",
    "              print('Training accuracy: %.1f%%' % accuracy( predictions, y_train[:, :]))\n",
    "              print('Validation accuracy: %.1f%%' % accuracy(predict_valid.eval(), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
