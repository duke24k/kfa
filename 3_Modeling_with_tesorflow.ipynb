{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forward_df = pd.read_csv('./data/forward.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    920.000000\n",
       "mean       6.590522\n",
       "std        0.398388\n",
       "min        5.820000\n",
       "25%        6.297500\n",
       "50%        6.560000\n",
       "75%        6.840000\n",
       "max        8.460000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_df['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6.7이 반이니깐 train용 데이터는 저 기준으로 자르자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_f_df = forward_df[forward_df['rating'] >= 6.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'age', 'asists', 'avgp', 'aw', 'blocks', 'clear',\n",
       "       'crosses', 'disp', 'drb', 'flag', 'fouled', 'fouls', 'full_time',\n",
       "       'goals', 'half_time', 'inter', 'keyp', 'league', 'longb', 'mins',\n",
       "       'motm', 'name', 'off', 'offsides', 'owng', 'player_number', 'position',\n",
       "       'ps_x', 'ps_y', 'rating', 'red', 'spg', 'tackles', 'tall', 'team_name',\n",
       "       'thrb', 'unstch', 'weight', 'yel', 'labeled_league'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_f_df0 = train_f_df.drop(['Unnamed: 0', 'flag', 'full_time', 'half_time', 'mins', 'motm', 'player_number', 'ps_y', 'rating', 'team_name', 'league'], axis=1)\n",
    "train_f_df0['league'] = train_f_df['league']\n",
    "train_f_df0['team_name'] = train_f_df['team_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_f_df0 = train_f_df0.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'asists', 'avgp', 'aw', 'blocks', 'clear', 'crosses', 'disp',\n",
       "       'drb', 'fouled', 'fouls', 'goals', 'inter', 'keyp', 'longb', 'name',\n",
       "       'off', 'offsides', 'owng', 'position', 'ps_x', 'red', 'spg', 'tackles',\n",
       "       'tall', 'thrb', 'unstch', 'weight', 'yel', 'labeled_league', 'league',\n",
       "       'team_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f_df0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_f_df1 = train_f_df0.drop(['league', 'team_name', 'name', 'position'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data, testing_data = train_test_split(train_f_df1.get_values(), train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_training_data = training_data[:,:-1]\n",
    "y_training_data = training_data[:, -1]\n",
    "y_training_data = y_training_data.reshape(361, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(361, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_testing_data = testing_data[:,:-1]\n",
    "y_testing_data = testing_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modeling with tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 27)\n",
      "0 5.306044578552246 85.32%\n",
      "1000 5.296889305114746 85.32%\n",
      "1999 5.287741661071777 85.32%\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = 2000\n",
    "LEARNING_RATE = 1e-8\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# Train the model\n",
    "feature_count = X_training_data.shape[1]\n",
    "x = tf.placeholder('float', shape=[None, feature_count], name='x')\n",
    "y_ = tf.placeholder('float', shape=[None, 1], name='y_')\n",
    "\n",
    "print(x.get_shape())\n",
    "\n",
    "nodes = 20\n",
    "\n",
    "w1 = weight_variable([feature_count, nodes])\n",
    "b1 = bias_variable([nodes])\n",
    "l1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "\n",
    "w2 = weight_variable([nodes, 1])\n",
    "b2 = bias_variable([1])\n",
    "y = tf.nn.sigmoid(tf.matmul(l1, w2) + b2)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(y_*tf.log(tf.maximum(0.00001, y)) + (1.0 - y_)*tf.log(tf.maximum(0.00001, 1.0-y)))\n",
    "reg = 0.01 * (tf.reduce_mean(tf.square(w1)) + tf.reduce_mean(tf.square(w2)))\n",
    "\n",
    "predict = (y > 0.5)\n",
    "\n",
    "correct_prediction = tf.equal(predict, (y_ > 0.5))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy + reg)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    feed={x:X_training_data, y_:y_training_data}\n",
    "    sess.run(train_step, feed_dict=feed)\n",
    "    if i % 1000 == 0 or i == ITERATIONS -1:\n",
    "        print('{} {} {:.2f}%'.format(i, sess.run(cross_entropy, feed_dict=feed), sess.run(accuracy, feed_dict=feed)*100))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 27)\n",
      "0 8.310705184936523 85.32%\n",
      "1000 8.302206993103027 85.32%\n",
      "1999 8.293720245361328 85.32%\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = 2000\n",
    "LEARNING_RATE = 1e-8\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# Train the model\n",
    "feature_count = X_training_data.shape[1]\n",
    "x = tf.placeholder('float', shape=[None, feature_count], name='x')\n",
    "y_ = tf.placeholder('float', shape=[None, 1], name='y_')\n",
    "\n",
    "print(x.get_shape())\n",
    "\n",
    "nodes = 20\n",
    "\n",
    "w1 = weight_variable([feature_count, nodes])\n",
    "b1 = bias_variable([nodes])\n",
    "l1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "\n",
    "w2 = weight_variable([nodes, 1])\n",
    "b2 = bias_variable([1])\n",
    "y = tf.nn.sigmoid(tf.matmul(l1, w2) + b2)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(y_*tf.log(tf.maximum(0.0000001, y)) + (1.0 - y_)*tf.log(tf.maximum(0.0000001, 1.0-y)))\n",
    "reg = 0.01 * (tf.reduce_mean(tf.square(w1)) + tf.reduce_mean(tf.square(w2)))\n",
    "\n",
    "predict = (y > 0.5)\n",
    "\n",
    "correct_prediction = tf.equal(predict, (y_ > 0.5))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy + reg)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    feed={x:X_training_data, y_:y_training_data}\n",
    "    sess.run(train_step, feed_dict=feed)\n",
    "    if i % 1000 == 0 or i == ITERATIONS -1:\n",
    "        print('{} {} {:.2f}%'.format(i, sess.run(cross_entropy, feed_dict=feed), sess.run(accuracy, feed_dict=feed)*100))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 27)\n",
      "0 16.18036651611328 85.32%\n",
      "1000 16.172746658325195 85.32%\n",
      "1999 16.164825439453125 85.32%\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = 2000\n",
    "LEARNING_RATE = 1e-8\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# Train the model\n",
    "feature_count = X_training_data.shape[1]\n",
    "x = tf.placeholder('float', shape=[None, feature_count], name='x')\n",
    "y_ = tf.placeholder('float', shape=[None, 1], name='y_')\n",
    "\n",
    "print(x.get_shape())\n",
    "\n",
    "nodes = 20\n",
    "\n",
    "w1 = weight_variable([feature_count, nodes])\n",
    "b1 = bias_variable([nodes])\n",
    "l1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "\n",
    "w2 = weight_variable([nodes, 1])\n",
    "b2 = bias_variable([1])\n",
    "y = tf.nn.sigmoid(tf.matmul(l1, w2) + b2)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(y_*tf.log(tf.maximum(0.00001, y)) + (1.0 - y_)*tf.log(tf.maximum(0.00001, 1.0-y)))\n",
    "reg = 0.01 * (tf.reduce_mean(tf.square(w1)) + tf.reduce_mean(tf.square(w2)))\n",
    "\n",
    "predict = (y > 0.5)\n",
    "\n",
    "correct_prediction = tf.equal(predict, (y_ > 0.5))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy + reg)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    feed={x:X_training_data, y_:y_training_data}\n",
    "    sess.run(train_step, feed_dict=feed)\n",
    "    if i % 1000 == 0 or i == ITERATIONS -1:\n",
    "        print('{} {} {:.2f}%'.format(i, sess.run(cross_entropy, feed_dict=feed), sess.run(accuracy, feed_dict=feed)*100))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCY output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_player_df = pd.read_csv(\"./merged_player.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LCY = total_player_df[total_player_df['name'] == \"Lee Chung-yong\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LCY0 = LCY.drop(['Unnamed: 0', 'Unnamed: 0.1', 'flag', 'full_time', 'half_time', 'mins', 'motm', 'player_number', 'ps_y', 'rating', 'team_name', 'league', 'position', 'name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_LCY = LCY0.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  27. ,    0. ,    0.5,    0.4,    0. ,    0.2,   85.9,    1.1,\n",
       "           0.3,    0.5,    0.3,    1. ,    0.5,    0.5,    0.5,    0. ,\n",
       "           0. ,    0. ,   85.9,    0. ,    0.4,    1.2,  180. ,    0.7,\n",
       "           0.5,   75. ,    0. ]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_LCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
